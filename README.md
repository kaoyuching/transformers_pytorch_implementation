# Implement Transformers with PyTorch

- [x] RMSNorm
- [x] Absolute Positional Encoding
- [x] Rotary Positional Encoding
- [x] Self Attention
- [x] Multi-head Self Attention
- [x] Transformers
